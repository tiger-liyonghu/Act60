#!/usr/bin/env python3
"""
01_find_companies.py â€” ä»Žç›‘ç®¡æœºæž„å®˜ç½‘èŽ·å–æ‰€æœ‰æŒç‰Œä¿é™©å…¬å¸åå•

ç”¨æ³•:
  python 01_find_companies.py HK
  python 01_find_companies.py SG
  python 01_find_companies.py ALL

æµç¨‹:
  ç›‘ç®¡æœºæž„å®˜ç½‘ï¼ˆIA / MASï¼‰
    â†’ Jina Reader æŠ“å–
    â†’ ä¿å­˜åŽŸå§‹æ–‡æœ¬åˆ° raw/{MARKET}_regulator_{date}.txt
    â†’ LLM æå–å…¬å¸å + å®˜ç½‘åœ°å€ï¼ˆä»…æå–åŽŸæ–‡ä¸­å‡ºçŽ°çš„å†…å®¹ï¼‰
    â†’ è¾“å‡º data/companies_{MARKET}.json

è¾“å‡ºå­—æ®µ:
  company_name      è‹±æ–‡å…¨åï¼ˆåŽŸæ–‡ï¼‰
  company_name_zh   ä¸­æ–‡åï¼ˆåŽŸæ–‡ä¸­æœ‰åˆ™å¡«ï¼Œå¦åˆ™ nullï¼‰
  website           å®˜ç½‘ URLï¼ˆåŽŸæ–‡ä¸­æ˜Žç¡®æ ‡æ³¨åˆ™å¡«ï¼Œå¦åˆ™ nullï¼‰
  license_type      è®¸å¯è¯ç±»åž‹ï¼ˆåŽŸæ–‡ï¼‰
  _source           åŽŸæ–‡ä¸­å¯¹åº”è¡Œï¼ˆç”¨äºŽæ ¸éªŒï¼‰
  market            å¸‚åœºä»£ç 
  regulator_source_url  æ¥æº URL
  scraped_at        æŠ“å–æ—¶é—´
  raw_file          åŽŸå§‹æ–‡æœ¬æ–‡ä»¶å
"""

import sys
import json
import time
import requests
from datetime import datetime, timezone
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent))
from config import MARKETS, JINA_BASE_URL, JINA_API_KEY, LLM_API_URL, LLM_API_KEY, LLM_MODEL, DATA_DIR, RAW_DIR

TODAY = datetime.now(timezone.utc).strftime("%Y%m%d")


# ===================== å·¥å…·å‡½æ•° =====================

def jina_fetch(url: str) -> str:
    """ä½¿ç”¨ Jina Reader æŠ“å–é¡µé¢ï¼Œè¿”å›ž markdown æ–‡æœ¬ã€‚"""
    jina_url = JINA_BASE_URL + url
    headers = {"Accept": "text/plain"}
    if JINA_API_KEY:
        headers["Authorization"] = f"Bearer {JINA_API_KEY}"
    print(f"  [Jina] æŠ“å–: {url}")
    resp = requests.get(jina_url, headers=headers, timeout=90)
    resp.raise_for_status()
    return resp.text


def llm_call(prompt: str) -> str:
    """è°ƒç”¨ LLMï¼ˆDeepSeek / OpenAI å…¼å®¹ï¼‰ï¼Œtemperature=0 æ¶ˆé™¤éšæœºæ€§ã€‚"""
    if not LLM_API_KEY:
        raise ValueError("è¯·è®¾ç½®çŽ¯å¢ƒå˜é‡ LLM_API_KEY")
    resp = requests.post(
        f"{LLM_API_URL}/chat/completions",
        headers={
            "Authorization": f"Bearer {LLM_API_KEY}",
            "Content-Type": "application/json",
        },
        json={
            "model": LLM_MODEL,
            "temperature": 0,
            "messages": [{"role": "user", "content": prompt}],
        },
        timeout=120,
    )
    resp.raise_for_status()
    return resp.json()["choices"][0]["message"]["content"]


def clean_json_response(text: str) -> str:
    """åŽ»é™¤ LLM è¾“å‡ºä¸­çš„ markdown ä»£ç å—æ ‡è®°ã€‚"""
    text = text.strip()
    if text.startswith("```"):
        lines = text.split("\n")
        text = "\n".join(lines[1:])
        if text.endswith("```"):
            text = text[:-3]
    return text.strip()


# ===================== LLM Prompt =====================

EXTRACT_COMPANIES_PROMPT = """ä½ æ˜¯æ•°æ®æå–åŠ©æ‰‹ã€‚è¯·ä»Žä»¥ä¸‹ç›‘ç®¡æœºæž„é¡µé¢åŽŸæ–‡ä¸­ï¼Œæå–æ‰€æœ‰æŒç‰Œä¿é™©å…¬å¸çš„ä¿¡æ¯ã€‚

ã€ä¸¥æ ¼è§„åˆ™ã€‘
1. åªæå–é¡µé¢ä¸­æ˜Žç¡®å‡ºçŽ°çš„æ–‡å­—ï¼Œä¸æŽ¨æ–­ã€ä¸è¡¥å……
2. company_name ä½¿ç”¨é¡µé¢åŽŸæ–‡ï¼ˆè‹±æ–‡ä¼˜å…ˆï¼‰
3. website åªå¡«å†™é¡µé¢ä¸­æ˜Žç¡®æ ‡æ³¨çš„å®˜ç½‘åœ°å€ï¼Œæ‰¾ä¸åˆ°è¿”å›ž null
4. license_type å¡«å†™é¡µé¢ä¸­å‡ºçŽ°çš„è®¸å¯è¯ç±»åž‹åŽŸæ–‡ï¼Œæ‰¾ä¸åˆ°è¿”å›ž null
5. _source å¡«å†™åŽŸæ–‡ä¸­æå–è¯¥å…¬å¸çš„å¯¹åº”è¡Œï¼Œç”¨äºŽäº‹åŽæ ¸éªŒ
6. ä¸è¦æ·»åŠ ä»»ä½•æœªåœ¨åŽŸæ–‡å‡ºçŽ°çš„å…¬å¸

å¸‚åœº: {market}
ç›‘ç®¡æœºæž„: {regulator}
æ¥æº URL: {source_url}

é¡µé¢åŽŸæ–‡:
{raw_text}

è¯·è¿”å›ž JSON æ•°ç»„ï¼š
[
  {{
    "company_name": "å…¬å¸è‹±æ–‡å…¨åï¼ˆåŽŸæ–‡ï¼‰",
    "company_name_zh": "å…¬å¸ä¸­æ–‡åï¼ˆåŽŸæ–‡ä¸­æœ‰åˆ™å¡«ï¼Œå¦åˆ™ nullï¼‰",
    "website": "å®˜ç½‘ URLï¼ˆåŽŸæ–‡ä¸­æœ‰åˆ™å¡«ï¼Œå¦åˆ™ nullï¼‰",
    "license_type": "è®¸å¯è¯ç±»åž‹ï¼ˆå¦‚ Long Term Insurer / General Insurerï¼ŒåŽŸæ–‡ï¼‰",
    "_source": "åŽŸæ–‡ä¸­æå–è¯¥å…¬å¸çš„å¯¹åº”è¡Œï¼ˆå®Œæ•´åŽŸå¥ï¼‰"
  }}
]

åªè¿”å›ž JSON æ•°ç»„ï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚æ‰¾ä¸åˆ°ä»»ä½•å…¬å¸åˆ™è¿”å›ž []ã€‚"""


# ===================== ä¸»æµç¨‹ =====================

def process_market(market_code: str):
    config = MARKETS.get(market_code)
    if not config:
        print(f"âŒ æœªçŸ¥å¸‚åœº: {market_code}ï¼Œå¯ç”¨: {list(MARKETS.keys())}")
        return

    print(f"\n{'='*60}")
    print(f"ðŸ“ å¸‚åœº: {config['name']} ({market_code})")
    print(f"ðŸ“‹ ç›‘ç®¡æœºæž„: {config['regulator_name']}")
    print(f"ðŸ”— æ¥æº: {config['regulator_url']}")
    print(f"{'='*60}")

    # Step 1: Jina æŠ“å–ç›‘ç®¡æœºæž„æ³¨å†Œåå•é¡µé¢
    try:
        raw_text = jina_fetch(config["regulator_url"])
    except Exception as e:
        print(f"âŒ æŠ“å–å¤±è´¥: {e}")
        return

    # Step 2: ä¿å­˜åŽŸå§‹æ–‡æœ¬ (L1 ç•™æ¡£)
    raw_file = RAW_DIR / f"{market_code}_regulator_{TODAY}.txt"
    raw_file.write_text(raw_text, encoding="utf-8")
    print(f"  [L1] åŽŸå§‹æ–‡æœ¬å·²ä¿å­˜ â†’ {raw_file.name} ({len(raw_text):,} å­—ç¬¦)")

    # Step 3: LLM æå–å…¬å¸åˆ—è¡¨
    # å¦‚æžœé¡µé¢è¿‡é•¿ï¼Œåˆ†æ®µå¤„ç†ï¼ˆæ¯æ®µ 12000 å­—ç¬¦ï¼‰
    chunk_size = 12000
    all_companies = []
    chunks = [raw_text[i:i+chunk_size] for i in range(0, len(raw_text), chunk_size)]

    print(f"  [LLM] åˆ† {len(chunks)} æ®µæå–å…¬å¸åˆ—è¡¨...")
    for idx, chunk in enumerate(chunks, 1):
        prompt = EXTRACT_COMPANIES_PROMPT.format(
            market=market_code,
            regulator=config["regulator_name"],
            source_url=config["regulator_url"],
            raw_text=chunk,
        )
        llm_response = ""
        try:
            llm_response = llm_call(prompt)
            cleaned = clean_json_response(llm_response)
            companies_chunk = json.loads(cleaned)
            all_companies.extend(companies_chunk)
            print(f"    æ®µ {idx}/{len(chunks)}: æå– {len(companies_chunk)} å®¶")
        except Exception as e:
            print(f"    æ®µ {idx} è§£æžå¤±è´¥: {e}")
            if llm_response:
                print(f"    LLM åŽŸå§‹è¾“å‡º: {llm_response[:300]}")
        time.sleep(1)

    # Step 4: åŽ»é‡ï¼ˆæŒ‰ company_nameï¼‰
    seen = set()
    unique = []
    for c in all_companies:
        key = c.get("company_name", "").strip().lower()
        if key and key not in seen:
            seen.add(key)
            unique.append(c)
    all_companies = unique

    # Step 5: æ·»åŠ å…ƒæ•°æ®
    scraped_at = datetime.now(timezone.utc).isoformat()
    for c in all_companies:
        c["market"] = market_code
        c["regulator_source_url"] = config["regulator_url"]
        c["scraped_at"] = scraped_at
        c["raw_file"] = raw_file.name

    # Step 6: ä¿å­˜ç»“æžœ
    out_file = DATA_DIR / f"companies_{market_code}.json"
    out_file.write_text(json.dumps(all_companies, ensure_ascii=False, indent=2), encoding="utf-8")

    print(f"\nâœ… å®Œæˆï¼å…±æ‰¾åˆ° {len(all_companies)} å®¶æŒç‰Œä¿é™©å…¬å¸ â†’ {out_file.name}")
    print("\nå‰ 10 å®¶é¢„è§ˆï¼š")
    for c in all_companies[:10]:
        website_str = c.get("website") or "ï¼ˆå®˜ç½‘æœªåœ¨åŽŸæ–‡åˆ—å‡ºï¼‰"
        print(f"  â€¢ {c['company_name']} | {website_str}")
    if len(all_companies) > 10:
        print(f"  ... å…± {len(all_companies)} å®¶")


def main():
    market_arg = sys.argv[1].upper() if len(sys.argv) > 1 else "ALL"

    if market_arg == "ALL":
        for code in MARKETS:
            process_market(code)
            time.sleep(3)
    else:
        process_market(market_arg)


if __name__ == "__main__":
    main()
